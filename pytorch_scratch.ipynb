{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T13:43:15.943743Z",
     "start_time": "2020-05-26T13:43:06.035660Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tensorboard_log_dir = os.path.join(os.environ[\"HOME\"],\"workspace\",\"tensorboard_logdir\")\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, explained_variance_score, mean_squared_log_error, mean_absolute_error, median_absolute_error, mean_squared_error, r2_score, confusion_matrix, roc_curve, accuracy_score, roc_auc_score, homogeneity_score, completeness_score, classification_report, silhouette_samples\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T13:58:35.308912Z",
     "start_time": "2020-05-26T13:56:44.863993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"run_executor.py\", line 750, in <module>\n",
      "    executor.execute()\n",
      "  File \"run_executor.py\", line 578, in execute\n",
      "    self.end_run()\n",
      "  File \"run_executor.py\", line 191, in end_run\n",
      "    self.dump_metrics_to_csv()\n",
      "  File \"run_executor.py\", line 292, in dump_metrics_to_csv\n",
      "    _ = pd.read_csv(os.path.join(results_file, \"results.csv\"))\n",
      "  File \"/Users/petersontylerd/.pyenv/versions/main37/lib/python3.7/site-packages/pandas/io/parsers.py\", line 676, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/petersontylerd/.pyenv/versions/main37/lib/python3.7/site-packages/pandas/io/parsers.py\", line 448, in _read\n",
      "    parser = TextFileReader(fp_or_buf, **kwds)\n",
      "  File \"/Users/petersontylerd/.pyenv/versions/main37/lib/python3.7/site-packages/pandas/io/parsers.py\", line 880, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/Users/petersontylerd/.pyenv/versions/main37/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1114, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/Users/petersontylerd/.pyenv/versions/main37/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1891, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 374, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: [Errno 2] File /Users/petersontylerd/pytorch_experiments/20200526_0857_FCNet/raw_logs/results.csv/results.csv does not exist: '/Users/petersontylerd/pytorch_experiments/20200526_0857_FCNet/raw_logs/results.csv/results.csv'\n"
     ]
    }
   ],
   "source": [
    "!python run_executor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pytorch_runs\n",
    "    - YYYYMMDD_HHMMS_NAME\n",
    "        - model\n",
    "            - best_model.pkl\n",
    "        - tensorboard\n",
    "        - images\n",
    "        - logs\n",
    "            - results_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T00:39:02.127430Z",
     "start_time": "2020-05-26T00:39:02.041707Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(os.path.join(os.environ[\"HOME\"], \"workspace\", \"pytorch_runs\",\"results.csv\")).sort_values([\"train_accuracy\",\"validation_accuracy\"], ascending=[False,False])[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:16:09.760387Z",
     "start_time": "2020-05-25T02:16:09.724274Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./results.csv', 'a') as f:\n",
    "    print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T02:18:58.714962Z",
     "start_time": "2020-05-25T02:18:58.676835Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    _ = pd.read_csv(\"./results.csv\")\n",
    "except:\n",
    "    print(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T15:17:54.836363Z",
     "start_time": "2020-05-24T15:17:54.825397Z"
    },
    "code_folding": [
     19
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imaging functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T15:17:54.844564Z",
     "start_time": "2020-05-24T15:17:54.839947Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_sample(inp, figsize=(20,20)):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(\n",
    "        inp,\n",
    "        interpolation=\"nearest\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T15:17:54.850650Z",
     "start_time": "2020-05-24T15:17:54.847843Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot sample image\n",
    "def plot_sample(image):\n",
    "    plt.imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T14:38:50.659777Z",
     "start_time": "2020-05-20T14:38:50.656277Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T15:17:54.878617Z",
     "start_time": "2020-05-24T15:17:54.853036Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load source files\n",
    "X_train, y_train = load_mnist(\n",
    "    path=os.path.join(os.environ[\"HOME\"], \"s3buckets\", \"mnist\"),\n",
    "    kind=\"train\"\n",
    ")\n",
    "\n",
    "# transformation instructions\n",
    "norm_mean = [0.1307]\n",
    "norm_std = [0.3801]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        norm_mean,\n",
    "        norm_std\n",
    "    ),\n",
    "])\n",
    "\n",
    "# load data into Pytorch Dataset\n",
    "train_data = MNISTDataset(\n",
    "    images=X_train[:6000,:],\n",
    "    targets=y_train[:6000],\n",
    "    transform=train_transform,\n",
    ")\n",
    "\n",
    "# create Pytorch DataLoader\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### review samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T15:17:55.184146Z",
     "start_time": "2020-05-24T15:17:54.881072Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# visualize image batch grid\n",
    "inputs, classes = next(iter(train_data_loader))\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "image_sample(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T15:17:55.314082Z",
     "start_time": "2020-05-24T15:17:55.186189Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = iter(train_data_loader.dataset.images)\n",
    "plot_sample(next(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T14:38:50.659777Z",
     "start_time": "2020-05-20T14:38:50.656277Z"
    }
   },
   "source": [
    "## Load validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T15:17:55.325820Z",
     "start_time": "2020-05-24T15:17:55.317994Z"
    }
   },
   "outputs": [],
   "source": [
    "# load source files\n",
    "X_valid, y_valid = load_mnist(\n",
    "    path=os.path.join(os.environ[\"HOME\"], \"s3buckets\", \"mnist\"),\n",
    "    kind=\"t10k\"\n",
    ")\n",
    "\n",
    "# transformation instructions\n",
    "norm_mean = [0.1307]\n",
    "norm_std = [0.3801]\n",
    "\n",
    "validation_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        norm_mean,\n",
    "        norm_std\n",
    "    )\n",
    "])\n",
    "\n",
    "# load data into Pytorch dataset\n",
    "validation_data = MNISTDataset(\n",
    "    images=X_valid,\n",
    "    targets=y_valid,\n",
    "    transform=validation_transform,\n",
    ")\n",
    "\n",
    "# create Pytorch DataLoader\n",
    "validation_data_loader = torch.utils.data.DataLoader(\n",
    "    validation_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    # sampler=weighted_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T15:17:55.620573Z",
     "start_time": "2020-05-24T15:17:55.328182Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualize image batch grid\n",
    "inputs, classes = next(iter(validation_data_loader))\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "image_sample(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T15:17:55.752027Z",
     "start_time": "2020-05-24T15:17:55.622658Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = iter(validation_data_loader.dataset.images)\n",
    "plot_sample(next(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T15:47:49.302701Z",
     "start_time": "2020-05-24T15:47:47.035100Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Parameter setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T03:17:33.899199Z",
     "start_time": "2020-05-23T03:17:33.893112Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set input kwargs as object attributes\n",
    "class ParamConfig:  \n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "# configure all necessary parameters\n",
    "model_params = ParamConfig(\n",
    "    model = FCNet,\n",
    "    model_name = \"FCNet\",\n",
    "#     model_object_dir = \"/content/drive/model_objects/20191202_1622_VGG16\",\n",
    "    model_object_dir = None,\n",
    "    optimizer = torch.optim.Adam,\n",
    "    criterion = F.cross_entropy,\n",
    "#     criterion = F.nll_loss,\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True),\n",
    "    valid_data_loader = torch.utils.data.DataLoader(valid_data, batch_size=128, shuffle=True),\n",
    "    cuda = True if torch.cuda.is_available() else False,\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    seed = 0,\n",
    "    lr = 0.001,\n",
    "    epochs = 50,\n",
    "    tensorboard_files = False,\n",
    "    verbose = True,\n",
    "    save_model_objects=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T04:00:56.885115Z",
     "start_time": "2020-05-23T04:00:56.880466Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ClassificationBoard():\n",
    "    \n",
    "    def __init__(self, root_log_dir, experiment_name):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.root_log_dir = root_log_dir        \n",
    "        self.log_dir = os.path.join(self.root_log_dir, self.experiment_name, datetime.today().strftime('%Y%m%d_%H%M'))\n",
    "        self.summary_writer = SummaryWriter(self.log_dir)\n",
    "        \n",
    "        \n",
    "    def log_scalars(self, scalars):\n",
    "        \n",
    "        for tag, value in scalars.items():\n",
    "            self.summary_writer.add_scalar(tag, value, step+1)\n",
    "\n",
    "test = ClassificationBoard(log_dir=tensorboard_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T03:54:18.468965Z",
     "start_time": "2020-05-23T03:54:18.464675Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.path.isdir(\"tensorboard_logdir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if (step+1) % 100 == 0:\n",
    "    print ('Step [{}/{}], Loss: {:.4f}, Acc: {:.2f}' \n",
    "           .format(step+1, total_step, loss.item(), accuracy.item()))\n",
    "\n",
    "    # ================================================================== #\n",
    "    #                        Tensorboard Logging                         #\n",
    "    # ================================================================== #\n",
    "\n",
    "    # 1. Log scalar values (scalar summary)\n",
    "    info = { 'loss': loss.item(), 'accuracy': accuracy.item() }\n",
    "\n",
    "    for tag, value in info.items():\n",
    "        logger.scalar_summary(tag, value, step+1)\n",
    "\n",
    "    # 2. Log values and gradients of the parameters (histogram summary)\n",
    "    for tag, value in model.named_parameters():\n",
    "        tag = tag.replace('.', '/')\n",
    "        logger.histo_summary(tag, value.data.cpu().numpy(), step+1)\n",
    "        logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), step+1)\n",
    "\n",
    "    # 3. Log training images (image summary)\n",
    "    info = { 'images': images.view(-1, 28, 28)[:10].cpu().numpy() }\n",
    "\n",
    "    for tag, images in info.items():\n",
    "        logger.image_summary(tag, images, step+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T15:25:28.513553Z",
     "start_time": "2020-05-20T15:25:28.494472Z"
    },
    "code_folding": [
     2,
     41,
     72,
     219
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PyTorchTrainer:\n",
    "\n",
    "    def __init__(self, config):\n",
    "\n",
    "        # random seed settings\n",
    "        self.seed = config.seed\n",
    "        torch.manual_seed(self.seed)\n",
    "        self.verbose = config.verbose\n",
    "\n",
    "        # data loaders\n",
    "        self.train_data_loader = config.train_data_loader\n",
    "        self.validation_data_loader = config.validation_data_loader\n",
    "\n",
    "        ## model object creation and device assignment\n",
    "        self.device = config.device\n",
    "\n",
    "        # if passing in the name of model Class object\n",
    "        if isinstance(config.model, type):\n",
    "            self.model = config.model().to(self.device)\n",
    "        # if model is already instantiated, or if transfer learning model is used\n",
    "        else:\n",
    "            self.model = config.model.to(self.device)\n",
    "\n",
    "        # name to use when saving model state\n",
    "        if config.model_name is not None:\n",
    "            self.model_name = config.model_name\n",
    "        else:\n",
    "            self.model_name = \"untitled\"\n",
    "\n",
    "        # model training settings\n",
    "        self.lr = config.lr\n",
    "        self.epochs = config.epochs\n",
    "        self.optimizer = config.optimizer(self.model.parameters(), lr=self.lr)\n",
    "        self.criterion = config.criterion\n",
    "\n",
    "        self.n_epochs_stop = 5\n",
    "        self.min_val_loss = np.inf\n",
    "        self.epochs_no_improve = 0\n",
    "\n",
    "        ## load previous state\n",
    "        # use checkpoint to load model state and associated objects\n",
    "        if config.model_object_dir is not None:\n",
    "            print(\">>> Resuming training...\")\n",
    "            self.model_object_dir = config.model_object_dir\n",
    "\n",
    "            # establish directory\n",
    "            self.model_dir = os.path.join(self.model_object_dir, \"models\")\n",
    "            self.object_dir = os.path.join(self.model_object_dir, \"objects\")\n",
    "            self.log_dir = os.path.join(self.model_object_dir, \"logs\")\n",
    "            self.log_train_dir = os.path.join(self.model_object_dir, \"logs\",\"train\")\n",
    "            self.log_validation_dir = os.path.join(self.model_object_dir, \"logs\",\"validation\")\n",
    "            \n",
    "            # load model\n",
    "            self.model.load_state_dict(torch.load(os.path.join(self.model_dir, os.listdir(self.model_dir)[0])))\n",
    "            self.model = self.model.to(self.device)\n",
    "            self.model_name = os.listdir(self.model_dir)[0].split(\".\")[0]\n",
    "            \n",
    "            # load statistics objects\n",
    "            self.running_avg_train_f1 = torch.load(os.path.join(self.object_dir, \"running_avg_train_f1.pt\"))\n",
    "            self.running_avg_train_precision = torch.load(os.path.join(self.object_dir, \"running_avg_train_precision.pt\"))\n",
    "            self.running_avg_train_recall = torch.load(os.path.join(self.object_dir, \"running_avg_train_recall.pt\"))\n",
    "            self.running_avg_train_accuracy = torch.load(os.path.join(self.object_dir, \"running_avg_train_accuracy.pt\"))\n",
    "            self.running_avg_train_loss = torch.load(os.path.join(self.object_dir, \"running_avg_train_loss.pt\"))\n",
    "            \n",
    "            self.running_avg_validation_f1 = torch.load(os.path.join(self.object_dir, \"running_avg_validation_f1.pt\"))\n",
    "            self.running_avg_validation_precision = torch.load(os.path.join(self.object_dir, \"running_avg_validation_precision.pt\"))\n",
    "            self.running_avg_validation_recall = torch.load(os.path.join(self.object_dir, \"running_avg_validation_recall.pt\"))\n",
    "            self.running_avg_validation_accuracy = torch.load(os.path.join(self.object_dir, \"running_avg_validation_accuracy.pt\"))\n",
    "            self.running_avg_validation_loss = torch.load(os.path.join(self.object_dir, \"running_avg_validation_loss.pt\"))\n",
    "\n",
    "            self.globaliter = torch.load(os.path.join(self.object_dir, \"globaliter.pt\"))\n",
    "    \n",
    "        else:\n",
    "            # directory tree for storing model attributes\n",
    "            current = datetime.today().strftime('%Y%m%d_%H%M') + \"_\" + self.model_name\n",
    "            \n",
    "            self.model_object_dir = os.path.join(os.getcwd(), \"model_objects\", current)\n",
    "            self.model_dir = os.path.join(self.model_object_dir, \"models\")\n",
    "            self.object_dir = os.path.join(self.model_object_dir, \"objects\")\n",
    "            self.log_dir = os.path.join(self.model_object_dir, \"logs\")\n",
    "            self.log_train_dir = os.path.join(self.model_object_dir, \"logs\",\"train\")\n",
    "            self.log_validation_dir = os.path.join(self.model_object_dir, \"logs\",\"validation\")\n",
    "            \n",
    "            os.makedirs(self.model_object_dir, exist_ok=True)\n",
    "            os.makedirs(self.model_dir, exist_ok=True)\n",
    "            os.makedirs(self.object_dir, exist_ok=True)\n",
    "            os.makedirs(self.log_dir, exist_ok=True)\n",
    "            os.makedirs(self.log_train_dir, exist_ok=True)\n",
    "            os.makedirs(self.log_validation_dir, exist_ok=True)\n",
    "            \n",
    "            self.globaliter = 0\n",
    "\n",
    "        # tensorboard\n",
    "        self.tensorboard_files = config.tensorboard_files\n",
    "        if self.tensorboard_files:\n",
    "            self.train_summary_writer = SummaryWriter(self.log_train_dir)\n",
    "            self.validation_summary_writer = SummaryWriter(self.log_validation_dir)\n",
    "        else:\n",
    "            self.train_summary_writer = None\n",
    "            self.validation_summary_writer = None\n",
    "            \n",
    "        self.beginning_time = time.time()\n",
    "\n",
    "    def train(self, epoch):\n",
    "        epoch_preds = []\n",
    "        epoch_targets = []\n",
    "\n",
    "        epoch_f1 = []\n",
    "        epoch_precision = []\n",
    "        epoch_recall = []\n",
    "        epoch_accuracy = []\n",
    "        epoch_loss = []\n",
    "\n",
    "        self.globaliter += 1\n",
    "        epoch_beginning_time = time.time()\n",
    "        \n",
    "        # sample batch number for data capture\n",
    "        num_batches = np.floor(len(self.train_data_loader.dataset.image_paths) / self.train_data_loader.batch_size)\n",
    "        sample_batch_idx = np.random.randint(0, num_batches)\n",
    "\n",
    "        self.model.train()\n",
    "        print(\"*\" * 100)\n",
    "        for batch_idx, (data, target) in enumerate(self.train_data_loader):\n",
    "            batch_beginning_time = time.time()\n",
    "\n",
    "            data = data.to(self.device)\n",
    "            target = target.to(self.device)\n",
    "\n",
    "            output = self.model(data)\n",
    "            train_loss = self.criterion(output, target)\n",
    "            epoch_loss.append(train_loss.item())\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            #Metrics\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            epoch_preds = epoch_preds + pred.detach().cpu().numpy().tolist()\n",
    "            epoch_targets = epoch_targets + target.detach().cpu().numpy().tolist()\n",
    "\n",
    "            metric_f1 = f1_score(epoch_targets, epoch_preds)\n",
    "            epoch_f1.append(metric_f1)\n",
    "\n",
    "            metric_precision = precision_score(epoch_targets, epoch_preds)\n",
    "            epoch_precision.append(metric_precision)\n",
    "\n",
    "            metric_recall = recall_score(epoch_targets, epoch_preds)\n",
    "            epoch_recall.append(metric_recall)\n",
    "\n",
    "            metric_accuracy = accuracy_score(epoch_targets, epoch_preds)\n",
    "            epoch_accuracy.append(metric_accuracy)\n",
    "\n",
    "            # print progress report\n",
    "            if self.verbose:\n",
    "                if batch_idx % 50 == 0 and batch_idx > 0:\n",
    "                    print(\"\\nTrain epoch: {} | Batch: {} | [Processed {}/{} ({:.0f}%)]\\n\\tLoss: {:.6f} | F1: {:.6f} | Precision: {:.6f} | Recall: {:.6f} | Accuracy: {:.6f}\".format(\n",
    "                        epoch, batch_idx, len(epoch_preds), len(self.train_data_loader.dataset),\n",
    "                        100. * len(epoch_preds) / len(self.train_data_loader.dataset), train_loss.item(), metric_f1,\n",
    "                        metric_precision, metric_recall, metric_accuracy))\n",
    "                    print(\"\\tBatch time elapsed: {}\\n\".format(self.train_timer(batch_beginning_time, time.time())))\n",
    "                    print(\"\\n\" + \"*\" * 10)\n",
    "\n",
    "            # # image batch sample\n",
    "            # if batch_idx == sample_batch_idx:\n",
    "            #     image_grid = torchvision.utils.make_grid(data.cpu())\n",
    "            #     self.train_summary_writer.add_image('train/Sample batch', image_grid, global_step=self.globaliter)\n",
    "            \n",
    "        # mark epoch end timestamp\n",
    "        epoch_ending_time = time.time()\n",
    "\n",
    "        try:\n",
    "            self.running_avg_train_f1.append((sum(epoch_f1) / len(epoch_f1)))\n",
    "            self.running_avg_train_precision.append((sum(epoch_precision) / len(epoch_precision)))\n",
    "            self.running_avg_train_recall.append((sum(epoch_recall) / len(epoch_recall)))\n",
    "            self.running_avg_train_accuracy.append((sum(epoch_accuracy) / len(epoch_accuracy)))\n",
    "            self.running_avg_train_loss.append((sum(epoch_loss) / len(epoch_loss)))\n",
    "\n",
    "            torch.save(self.running_avg_train_f1, os.path.join(self.object_dir, \"running_avg_train_f1.pt\"))\n",
    "            torch.save(self.running_avg_train_precision, os.path.join(self.object_dir, \"running_avg_train_precision.pt\"))\n",
    "            torch.save(self.running_avg_train_recall, os.path.join(self.object_dir, \"running_avg_train_recall.pt\"))\n",
    "            torch.save(self.running_avg_train_accuracy, os.path.join(self.object_dir, \"running_avg_train_accuracy.pt\"))\n",
    "            torch.save(self.running_avg_train_loss, os.path.join(self.object_dir, \"running_avg_train_loss.pt\"))\n",
    "\n",
    "            # tensorboard\n",
    "            if self.tensorboard_files:\n",
    "                self.train_summary_writer.add_scalar('train/F1', self.running_avg_train_f1[-1], global_step=self.globaliter)\n",
    "                self.train_summary_writer.add_scalar('train/Precision', self.running_avg_train_precision[-1], global_step=self.globaliter)\n",
    "                self.train_summary_writer.add_scalar('train/Recall', self.running_avg_train_recall[-1], global_step=self.globaliter)\n",
    "                self.train_summary_writer.add_scalar('train/Accuracy', self.running_avg_train_accuracy[-1], global_step=self.globaliter)\n",
    "                self.train_summary_writer.add_scalar('train/Loss', self.running_avg_train_loss[-1], global_step=self.globaliter)\n",
    "\n",
    "                self.train_summary_writer.add_scalar('F1', self.running_avg_train_f1[-1], global_step=self.globaliter)\n",
    "                self.train_summary_writer.add_scalar('Precision', self.running_avg_train_precision[-1], global_step=self.globaliter)\n",
    "                self.train_summary_writer.add_scalar('Recall', self.running_avg_train_recall[-1], global_step=self.globaliter)\n",
    "                self.train_summary_writer.add_scalar('Accuracy', self.running_avg_train_accuracy[-1], global_step=self.globaliter)\n",
    "                self.train_summary_writer.add_scalar('Loss', self.running_avg_train_loss[-1], global_step=self.globaliter)\n",
    "                                \n",
    "                self.train_summary_writer.flush()\n",
    "\n",
    "        except AttributeError:\n",
    "            self.running_avg_train_f1 = [(sum(epoch_f1) / len(epoch_f1))]\n",
    "            self.running_avg_train_precision = [(sum(epoch_precision) / len(epoch_precision))]\n",
    "            self.running_avg_train_recall = [(sum(epoch_recall) / len(epoch_recall))]\n",
    "            self.running_avg_train_accuracy = [(sum(epoch_accuracy) / len(epoch_accuracy))]\n",
    "            self.running_avg_train_loss = [(sum(epoch_loss) / len(epoch_loss))]\n",
    "\n",
    "        # print progress report\n",
    "        if self.verbose:\n",
    "            print(\"*\" * 10 + \"\\n\")\n",
    "            print(\"Train epoch: {} \\n\\tLoss: {:.6f} | F1: {:.6f} | Precision: {:.6f} | Recall: {:.6f} | Accuracy: {:.6f}\\n\".format(\n",
    "                        epoch, self.running_avg_train_loss[-1], self.running_avg_train_f1[-1],\n",
    "                        self.running_avg_train_precision[-1], self.running_avg_train_recall[-1], self.running_avg_train_accuracy[-1]))\n",
    "            print(\"\\tEpoch time elapsed: {}\".format(self.train_timer(epoch_beginning_time, epoch_ending_time)))\n",
    "            print(\"\\tTotal time elapsed: {}\".format(self.train_timer(self.beginning_time, time.time())))\n",
    "        \n",
    "        # capture globaliter\n",
    "        torch.save(self.globaliter, os.path.join(self.object_dir, \"globaliter.pt\"))\n",
    "\n",
    "    def validation(self, epoch):\n",
    "        epoch_preds = []\n",
    "        epoch_targets = []\n",
    "\n",
    "        epoch_f1 = []\n",
    "        epoch_precision = []\n",
    "        epoch_recall = []\n",
    "        epoch_accuracy = []\n",
    "        epoch_loss = []\n",
    "        \n",
    "        # sample batch number for data capture\n",
    "        num_batches = np.floor(len(self.validation_data_loader.dataset.image_paths) / self.validation_data_loader.batch_size)\n",
    "        sample_batch_idx = np.random.randint(0, num_batches)\n",
    "\n",
    "        # turn off gradients\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for batch_idx, (data, target) in enumerate(self.validation_data_loader):\n",
    "                # reshape data as needed and send data to GPU if available\n",
    "                data = data.to(self.device)\n",
    "                target = target.to(self.device)\n",
    "\n",
    "                # generate predictions\n",
    "                output = self.model(data)\n",
    "\n",
    "                validation_loss = self.criterion(output, target)\n",
    "                epoch_loss.append(validation_loss.item())\n",
    "\n",
    "                #Metrics\n",
    "                _, pred = torch.max(output, dim=1)\n",
    "                epoch_preds = epoch_preds + pred.detach().cpu().numpy().tolist()\n",
    "                epoch_targets = epoch_targets + target.detach().cpu().numpy().tolist()\n",
    "\n",
    "                metric_f1 = f1_score(epoch_targets, epoch_preds)\n",
    "                epoch_f1.append(metric_f1)\n",
    "\n",
    "                metric_precision = precision_score(epoch_targets, epoch_preds)\n",
    "                epoch_precision.append(metric_precision)\n",
    "\n",
    "                metric_recall = recall_score(epoch_targets, epoch_preds)\n",
    "                epoch_recall.append(metric_recall)\n",
    "\n",
    "                metric_accuracy = accuracy_score(epoch_targets, epoch_preds)\n",
    "                epoch_accuracy.append(metric_accuracy)\n",
    "            \n",
    "            # #\n",
    "            # if batch_idx == sample_batch_idx:\n",
    "            #     image_grid = torchvision.utils.make_grid(data.cpu())\n",
    "            #     self.validation_summary_writer.add_image('validation/Sample batch', image_grid, global_step=self.globaliter)\n",
    "                \n",
    "            # \n",
    "            try:\n",
    "                self.running_avg_validation_f1.append((sum(epoch_f1) / len(epoch_f1)))\n",
    "                self.running_avg_validation_precision.append((sum(epoch_precision) / len(epoch_precision)))\n",
    "                self.running_avg_validation_recall.append((sum(epoch_recall) / len(epoch_recall)))\n",
    "                self.running_avg_validation_accuracy.append((sum(epoch_accuracy) / len(epoch_accuracy)))\n",
    "                self.running_avg_validation_loss.append((sum(epoch_loss) / len(epoch_loss)))\n",
    "\n",
    "                torch.save(self.running_avg_validation_f1, os.path.join(self.object_dir, \"running_avg_validation_f1.pt\"))\n",
    "                torch.save(self.running_avg_validation_precision, os.path.join(self.object_dir, \"running_avg_validation_precision.pt\"))\n",
    "                torch.save(self.running_avg_validation_recall, os.path.join(self.object_dir, \"running_avg_validation_recall.pt\"))\n",
    "                torch.save(self.running_avg_validation_accuracy, os.path.join(self.object_dir, \"running_avg_validation_accuracy.pt\"))\n",
    "                torch.save(self.running_avg_validation_loss, os.path.join(self.object_dir, \"running_avg_validation_loss.pt\"))\n",
    "\n",
    "                # tensorboard\n",
    "                if self.tensorboard_files:\n",
    "                    # validation panel - one scalar per metric per plot\n",
    "                    self.validation_summary_writer.add_scalar('validation/F1', self.running_avg_validation_f1[-1], global_step=self.globaliter)\n",
    "                    self.validation_summary_writer.add_scalar('validation/Precision', self.running_avg_validation_precision[-1], global_step=self.globaliter)\n",
    "                    self.validation_summary_writer.add_scalar('validation/Recall', self.running_avg_validation_recall[-1], global_step=self.globaliter)\n",
    "                    self.validation_summary_writer.add_scalar('validation/Accuracy', self.running_avg_validation_accuracy[-1], global_step=self.globaliter)\n",
    "                    self.validation_summary_writer.add_scalar('validation/Loss', self.running_avg_validation_loss[-1], global_step=self.globaliter)\n",
    "\n",
    "                    # metric-specific plots\n",
    "                    self.validation_summary_writer.add_scalar('F1', self.running_avg_validation_f1[-1], global_step=self.globaliter)\n",
    "                    self.validation_summary_writer.add_scalar('Precision', self.running_avg_validation_precision[-1], global_step=self.globaliter)\n",
    "                    self.validation_summary_writer.add_scalar('Recall', self.running_avg_validation_recall[-1], global_step=self.globaliter)\n",
    "                    self.validation_summary_writer.add_scalar('Accuracy', self.running_avg_validation_accuracy[-1], global_step=self.globaliter)\n",
    "                    self.validation_summary_writer.add_scalar('Loss', self.running_avg_validation_loss[-1], global_step=self.globaliter)\n",
    "                    \n",
    "                    self.validation_summary_writer.flush()\n",
    "\n",
    "            # create statistics object and continue\n",
    "            except AttributeError:\n",
    "                self.running_avg_validation_f1 = [(sum(epoch_f1) / len(epoch_f1))]\n",
    "                self.running_avg_validation_precision = [(sum(epoch_precision) / len(epoch_precision))]\n",
    "                self.running_avg_validation_recall = [(sum(epoch_recall) / len(epoch_recall))]\n",
    "                self.running_avg_validation_accuracy = [(sum(epoch_accuracy) / len(epoch_accuracy))]\n",
    "                self.running_avg_validation_loss = [(sum(epoch_loss) / len(epoch_loss))]\n",
    "                \n",
    "            # print progress report\n",
    "            if self.verbose:\n",
    "                print(\"\\nValidation epoch: {} \\n\\tLoss: {:.6f} | F1: {:.6f} | Precision: {:.6f} | Recall: {:.6f} | Accuracy: {:.6f}\\n\".format(\n",
    "                        epoch, self.running_avg_validation_loss[-1], self.running_avg_validation_f1[-1],\n",
    "                        self.running_avg_validation_precision[-1], self.running_avg_validation_recall[-1], self.running_avg_validation_accuracy[-1]))\n",
    "        \n",
    "            # early stopping\n",
    "            if self.running_avg_validation_loss[-1] < self.min_val_loss:\n",
    "                # Save the model checkpoint\n",
    "                torch.save(self.model.state_dict(), os.path.join(self.model_dir, \"{}.pt\".format(self.model_name)))\n",
    "                self.epochs_no_improve = 0\n",
    "                self.min_val_loss = self.running_avg_validation_loss[-1]\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(\">>> Improved - saving model\\n\\n\\n\")\n",
    "\n",
    "            else:\n",
    "                self.epochs_no_improve += 1\n",
    "                if self.verbose:\n",
    "                    print(\">>> No improvement - {} consecutive epochs\\n\\n\\n\".format(self.epochs_no_improve))\n",
    "                if self.epochs_no_improve == self.n_epochs_stop:\n",
    "                    if self.verbose:\n",
    "                        print(\"\\n!!! Early stopping - {} epochs without improvement\\n\".format(self.n_epochs_stop))\n",
    "                self.running_avg_validation_loss = []\n",
    "                    \n",
    "    def train_timer(self, start, end):\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        return \"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T15:29:17.887861Z",
     "start_time": "2020-05-20T15:25:30.758839Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### fit model\n",
    "# instantiate model object\n",
    "trainer = PyTorchTrainer(config=model_params)\n",
    "\n",
    "# iterate fitting procedure over specified epoch count\n",
    "for epoch in range(1, trainer.epochs + 1):\n",
    "    trainer.train(epoch)\n",
    "    trainer.validation(epoch)\n",
    "trainer.train_summary_writer.close()\n",
    "trainer.validation_summary_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PyTorchTrainer:\n",
    "\n",
    "    def __init__(self, config):\n",
    "\n",
    "        # random seed settings\n",
    "        self.seed = config.seed\n",
    "        torch.manual_seed(self.seed)\n",
    "        self.verbose = config.verbose\n",
    "\n",
    "        # data loaders\n",
    "        self.train_data_loader = config.train_data_loader\n",
    "        self.validation_data_loader = config.validation_data_loader\n",
    "\n",
    "        ## model object creation and device assignment\n",
    "        self.device = config.device\n",
    "\n",
    "        # if passing in the name of model Class object\n",
    "        if isinstance(config.model, type):\n",
    "            self.model = config.model().to(self.device)\n",
    "        # if model is already instantiated, or if transfer learning model is used\n",
    "        else:\n",
    "            self.model = config.model.to(self.device)\n",
    "\n",
    "        # name to use when saving model state\n",
    "        if config.model_name is not None:\n",
    "            self.model_name = config.model_name\n",
    "        else:\n",
    "            self.model_name = \"untitled\"\n",
    "\n",
    "        # model training settings\n",
    "        self.lr = config.lr\n",
    "        self.epochs = config.epochs\n",
    "        self.optimizer = config.optimizer(self.model.parameters(), lr=self.lr)\n",
    "        self.criterion = config.criterion\n",
    "\n",
    "        self.n_epochs_stop = 5\n",
    "        self.min_val_loss = np.inf\n",
    "        self.epochs_no_improve = 0\n",
    "\n",
    "        ## load previous state\n",
    "        # use checkpoint to load model state and associated objects\n",
    "        if config.model_object_dir is not None:\n",
    "            print(\">>> Resuming training...\")\n",
    "            self.model_object_dir = config.model_object_dir\n",
    "\n",
    "            # establish directory\n",
    "            self.model_dir = os.path.join(self.model_object_dir, \"models\")\n",
    "            self.object_dir = os.path.join(self.model_object_dir, \"objects\")\n",
    "            self.log_dir = os.path.join(self.model_object_dir, \"logs\")\n",
    "            self.log_train_dir = os.path.join(self.model_object_dir, \"logs\",\"train\")\n",
    "            self.log_validation_dir = os.path.join(self.model_object_dir, \"logs\",\"validation\")\n",
    "            \n",
    "            # load model\n",
    "            self.model.load_state_dict(torch.load(os.path.join(self.model_dir, os.listdir(self.model_dir)[0])))\n",
    "            self.model = self.model.to(self.device)\n",
    "            self.model_name = os.listdir(self.model_dir)[0].split(\".\")[0]\n",
    "            \n",
    "            # load statistics objects\n",
    "            self.running_avg_train_f1 = torch.load(os.path.join(self.object_dir, \"running_avg_train_f1.pt\"))\n",
    "            self.running_avg_train_precision = torch.load(os.path.join(self.object_dir, \"running_avg_train_precision.pt\"))\n",
    "            self.running_avg_train_recall = torch.load(os.path.join(self.object_dir, \"running_avg_train_recall.pt\"))\n",
    "            self.running_avg_train_accuracy = torch.load(os.path.join(self.object_dir, \"running_avg_train_accuracy.pt\"))\n",
    "            self.running_avg_train_loss = torch.load(os.path.join(self.object_dir, \"running_avg_train_loss.pt\"))\n",
    "            \n",
    "            self.running_avg_validation_f1 = torch.load(os.path.join(self.object_dir, \"running_avg_validation_f1.pt\"))\n",
    "            self.running_avg_validation_precision = torch.load(os.path.join(self.object_dir, \"running_avg_validation_precision.pt\"))\n",
    "            self.running_avg_validation_recall = torch.load(os.path.join(self.object_dir, \"running_avg_validation_recall.pt\"))\n",
    "            self.running_avg_validation_accuracy = torch.load(os.path.join(self.object_dir, \"running_avg_validation_accuracy.pt\"))\n",
    "            self.running_avg_validation_loss = torch.load(os.path.join(self.object_dir, \"running_avg_validation_loss.pt\"))\n",
    "\n",
    "            self.globaliter = torch.load(os.path.join(self.object_dir, \"globaliter.pt\"))\n",
    "    \n",
    "        else:\n",
    "            # directory tree for storing model attributes\n",
    "            current = datetime.today().strftime('%Y%m%d_%H%M') + \"_\" + self.model_name\n",
    "            \n",
    "            self.model_object_dir = os.path.join(os.getcwd(), \"model_objects\", current)\n",
    "            self.model_dir = os.path.join(self.model_object_dir, \"models\")\n",
    "            self.object_dir = os.path.join(self.model_object_dir, \"objects\")\n",
    "            self.log_dir = os.path.join(self.model_object_dir, \"logs\")\n",
    "            self.log_train_dir = os.path.join(self.model_object_dir, \"logs\",\"train\")\n",
    "            self.log_validation_dir = os.path.join(self.model_object_dir, \"logs\",\"validation\")\n",
    "            \n",
    "            os.makedirs(self.model_object_dir, exist_ok=True)\n",
    "            os.makedirs(self.model_dir, exist_ok=True)\n",
    "            os.makedirs(self.object_dir, exist_ok=True)\n",
    "            os.makedirs(self.log_dir, exist_ok=True)\n",
    "            os.makedirs(self.log_train_dir, exist_ok=True)\n",
    "            os.makedirs(self.log_validation_dir, exist_ok=True)\n",
    "            \n",
    "            self.globaliter = 0\n",
    "\n",
    "        # tensorboard\n",
    "        self.tensorboard_files = config.tensorboard_files\n",
    "        if self.tensorboard_files:\n",
    "            self.train_summary_writer = SummaryWriter(self.log_train_dir)\n",
    "            self.validation_summary_writer = SummaryWriter(self.log_validation_dir)\n",
    "        else:\n",
    "            self.train_summary_writer = None\n",
    "            self.validation_summary_writer = None\n",
    "            \n",
    "        self.beginning_time = time.time()\n",
    "\n",
    "    def train(self, epoch):\n",
    "        epoch_preds = []\n",
    "        epoch_targets = []\n",
    "\n",
    "        epoch_f1 = []\n",
    "        epoch_precision = []\n",
    "        epoch_recall = []\n",
    "        epoch_accuracy = []\n",
    "        epoch_loss = []\n",
    "\n",
    "        self.globaliter += 1\n",
    "        epoch_beginning_time = time.time()\n",
    "        \n",
    "        # sample batch number for data capture\n",
    "        num_batches = np.floor(len(self.train_data_loader.dataset.image_paths) / self.train_data_loader.batch_size)\n",
    "        sample_batch_idx = np.random.randint(0, num_batches)\n",
    "\n",
    "        self.model.train()\n",
    "        print(\"*\" * 100)\n",
    "        for batch_idx, (data, target) in enumerate(self.train_data_loader):\n",
    "            batch_beginning_time = time.time()\n",
    "\n",
    "            data = data.to(self.device)\n",
    "            target = target.to(self.device)\n",
    "\n",
    "            output = self.model(data)\n",
    "            train_loss = self.criterion(output, target)\n",
    "            epoch_loss.append(train_loss.item())\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            #Metrics\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            epoch_preds = epoch_preds + pred.detach().cpu().numpy().tolist()\n",
    "            epoch_targets = epoch_targets + target.detach().cpu().numpy().tolist()\n",
    "\n",
    "            metric_f1 = f1_score(epoch_targets, epoch_preds)\n",
    "            epoch_f1.append(metric_f1)\n",
    "\n",
    "            metric_precision = precision_score(epoch_targets, epoch_preds)\n",
    "            epoch_precision.append(metric_precision)\n",
    "\n",
    "            metric_recall = recall_score(epoch_targets, epoch_preds)\n",
    "            epoch_recall.append(metric_recall)\n",
    "\n",
    "            metric_accuracy = accuracy_score(epoch_targets, epoch_preds)\n",
    "            epoch_accuracy.append(metric_accuracy)\n",
    "\n",
    "            # print progress report\n",
    "            if self.verbose:\n",
    "                if batch_idx % 50 == 0 and batch_idx > 0:\n",
    "                    print(\"\\nTrain epoch: {} | Batch: {} | [Processed {}/{} ({:.0f}%)]\\n\\tLoss: {:.6f} | F1: {:.6f} | Precision: {:.6f} | Recall: {:.6f} | Accuracy: {:.6f}\".format(\n",
    "                        epoch, batch_idx, len(epoch_preds), len(self.train_data_loader.dataset),\n",
    "                        100. * len(epoch_preds) / len(self.train_data_loader.dataset), train_loss.item(), metric_f1,\n",
    "                        metric_precision, metric_recall, metric_accuracy))\n",
    "                    print(\"\\tBatch time elapsed: {}\\n\".format(self.train_timer(batch_beginning_time, time.time())))\n",
    "                    print(\"\\n\" + \"*\" * 10)\n",
    "\n",
    "            # # image batch sample\n",
    "            # if batch_idx == sample_batch_idx:\n",
    "            #     image_grid = torchvision.utils.make_grid(data.cpu())\n",
    "            #     self.train_summary_writer.add_image('train/Sample batch', image_grid, global_step=self.globaliter)\n",
    "            \n",
    "        # mark epoch end timestamp\n",
    "        epoch_ending_time = time.time()\n",
    "\n",
    "        try:\n",
    "            self.running_avg_train_f1.append((sum(epoch_f1) / len(epoch_f1)))\n",
    "            self.running_avg_train_precision.append((sum(epoch_precision) / len(epoch_precision)))\n",
    "            self.running_avg_train_recall.append((sum(epoch_recall) / len(epoch_recall)))\n",
    "            self.running_avg_train_accuracy.append((sum(epoch_accuracy) / len(epoch_accuracy)))\n",
    "            self.running_avg_train_loss.append((sum(epoch_loss) / len(epoch_loss)))\n",
    "\n",
    "            torch.save(self.running_avg_train_f1, os.path.join(self.object_dir, \"running_avg_train_f1.pt\"))\n",
    "            torch.save(self.running_avg_train_precision, os.path.join(self.object_dir, \"running_avg_train_precision.pt\"))\n",
    "            torch.save(self.running_avg_train_recall, os.path.join(self.object_dir, \"running_avg_train_recall.pt\"))\n",
    "            torch.save(self.running_avg_train_accuracy, os.path.join(self.object_dir, \"running_avg_train_accuracy.pt\"))\n",
    "            torch.save(self.running_avg_train_loss, os.path.join(self.object_dir, \"running_avg_train_loss.pt\"))\n",
    "\n",
    "            # tensorboard\n",
    "            if self.tensorboard_files:\n",
    "                self.train_summary_writer.add_scalar('train/F1', self.running_avg_train_f1[-1], global_step=self.globaliter)\n",
    "                self.train_summary_writer.add_scalar('train/Precision', self.running_avg_train_precision[-1], global_step=self.globaliter)\n",
    "                self.train_summary_writer.add_scalar('train/Recall', self.running_avg_train_recall[-1], global_step=self.globaliter)\n",
    "                self.train_summary_writer.add_scalar('train/Accuracy', self.running_avg_train_accuracy[-1], global_step=self.globaliter)\n",
    "                self.train_summary_writer.add_scalar('train/Loss', self.running_avg_train_loss[-1], global_step=self.globaliter)\n",
    "\n",
    "                self.train_summary_writer.add_scalar('F1', self.running_avg_train_f1[-1], global_step=self.globaliter)\n",
    "                self.train_summary_writer.add_scalar('Precision', self.running_avg_train_precision[-1], global_step=self.globaliter)\n",
    "                self.train_summary_writer.add_scalar('Recall', self.running_avg_train_recall[-1], global_step=self.globaliter)\n",
    "                self.train_summary_writer.add_scalar('Accuracy', self.running_avg_train_accuracy[-1], global_step=self.globaliter)\n",
    "                self.train_summary_writer.add_scalar('Loss', self.running_avg_train_loss[-1], global_step=self.globaliter)\n",
    "                                \n",
    "                self.train_summary_writer.flush()\n",
    "\n",
    "        except AttributeError:\n",
    "            self.running_avg_train_f1 = [(sum(epoch_f1) / len(epoch_f1))]\n",
    "            self.running_avg_train_precision = [(sum(epoch_precision) / len(epoch_precision))]\n",
    "            self.running_avg_train_recall = [(sum(epoch_recall) / len(epoch_recall))]\n",
    "            self.running_avg_train_accuracy = [(sum(epoch_accuracy) / len(epoch_accuracy))]\n",
    "            self.running_avg_train_loss = [(sum(epoch_loss) / len(epoch_loss))]\n",
    "\n",
    "        # print progress report\n",
    "        if self.verbose:\n",
    "            print(\"*\" * 10 + \"\\n\")\n",
    "            print(\"Train epoch: {} \\n\\tLoss: {:.6f} | F1: {:.6f} | Precision: {:.6f} | Recall: {:.6f} | Accuracy: {:.6f}\\n\".format(\n",
    "                        epoch, self.running_avg_train_loss[-1], self.running_avg_train_f1[-1],\n",
    "                        self.running_avg_train_precision[-1], self.running_avg_train_recall[-1], self.running_avg_train_accuracy[-1]))\n",
    "            print(\"\\tEpoch time elapsed: {}\".format(self.train_timer(epoch_beginning_time, epoch_ending_time)))\n",
    "            print(\"\\tTotal time elapsed: {}\".format(self.train_timer(self.beginning_time, time.time())))\n",
    "        \n",
    "        # capture globaliter\n",
    "        torch.save(self.globaliter, os.path.join(self.object_dir, \"globaliter.pt\"))\n",
    "\n",
    "    def validation(self, epoch):\n",
    "        epoch_preds = []\n",
    "        epoch_targets = []\n",
    "\n",
    "        epoch_f1 = []\n",
    "        epoch_precision = []\n",
    "        epoch_recall = []\n",
    "        epoch_accuracy = []\n",
    "        epoch_loss = []\n",
    "        \n",
    "        # sample batch number for data capture\n",
    "        num_batches = np.floor(len(self.validation_data_loader.dataset.image_paths) / self.validation_data_loader.batch_size)\n",
    "        sample_batch_idx = np.random.randint(0, num_batches)\n",
    "\n",
    "        # turn off gradients\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for batch_idx, (data, target) in enumerate(self.validation_data_loader):\n",
    "                # reshape data as needed and send data to GPU if available\n",
    "                data = data.to(self.device)\n",
    "                target = target.to(self.device)\n",
    "\n",
    "                # generate predictions\n",
    "                output = self.model(data)\n",
    "\n",
    "                validation_loss = self.criterion(output, target)\n",
    "                epoch_loss.append(validation_loss.item())\n",
    "\n",
    "                #Metrics\n",
    "                _, pred = torch.max(output, dim=1)\n",
    "                epoch_preds = epoch_preds + pred.detach().cpu().numpy().tolist()\n",
    "                epoch_targets = epoch_targets + target.detach().cpu().numpy().tolist()\n",
    "\n",
    "                metric_f1 = f1_score(epoch_targets, epoch_preds)\n",
    "                epoch_f1.append(metric_f1)\n",
    "\n",
    "                metric_precision = precision_score(epoch_targets, epoch_preds)\n",
    "                epoch_precision.append(metric_precision)\n",
    "\n",
    "                metric_recall = recall_score(epoch_targets, epoch_preds)\n",
    "                epoch_recall.append(metric_recall)\n",
    "\n",
    "                metric_accuracy = accuracy_score(epoch_targets, epoch_preds)\n",
    "                epoch_accuracy.append(metric_accuracy)\n",
    "            \n",
    "            # #\n",
    "            # if batch_idx == sample_batch_idx:\n",
    "            #     image_grid = torchvision.utils.make_grid(data.cpu())\n",
    "            #     self.validation_summary_writer.add_image('validation/Sample batch', image_grid, global_step=self.globaliter)\n",
    "                \n",
    "            # \n",
    "            try:\n",
    "                self.running_avg_validation_f1.append((sum(epoch_f1) / len(epoch_f1)))\n",
    "                self.running_avg_validation_precision.append((sum(epoch_precision) / len(epoch_precision)))\n",
    "                self.running_avg_validation_recall.append((sum(epoch_recall) / len(epoch_recall)))\n",
    "                self.running_avg_validation_accuracy.append((sum(epoch_accuracy) / len(epoch_accuracy)))\n",
    "                self.running_avg_validation_loss.append((sum(epoch_loss) / len(epoch_loss)))\n",
    "\n",
    "                torch.save(self.running_avg_validation_f1, os.path.join(self.object_dir, \"running_avg_validation_f1.pt\"))\n",
    "                torch.save(self.running_avg_validation_precision, os.path.join(self.object_dir, \"running_avg_validation_precision.pt\"))\n",
    "                torch.save(self.running_avg_validation_recall, os.path.join(self.object_dir, \"running_avg_validation_recall.pt\"))\n",
    "                torch.save(self.running_avg_validation_accuracy, os.path.join(self.object_dir, \"running_avg_validation_accuracy.pt\"))\n",
    "                torch.save(self.running_avg_validation_loss, os.path.join(self.object_dir, \"running_avg_validation_loss.pt\"))\n",
    "\n",
    "                # tensorboard\n",
    "                if self.tensorboard_files:\n",
    "                    # validation panel - one scalar per metric per plot\n",
    "                    self.validation_summary_writer.add_scalar('validation/F1', self.running_avg_validation_f1[-1], global_step=self.globaliter)\n",
    "                    self.validation_summary_writer.add_scalar('validation/Precision', self.running_avg_validation_precision[-1], global_step=self.globaliter)\n",
    "                    self.validation_summary_writer.add_scalar('validation/Recall', self.running_avg_validation_recall[-1], global_step=self.globaliter)\n",
    "                    self.validation_summary_writer.add_scalar('validation/Accuracy', self.running_avg_validation_accuracy[-1], global_step=self.globaliter)\n",
    "                    self.validation_summary_writer.add_scalar('validation/Loss', self.running_avg_validation_loss[-1], global_step=self.globaliter)\n",
    "\n",
    "                    # metric-specific plots\n",
    "                    self.validation_summary_writer.add_scalar('F1', self.running_avg_validation_f1[-1], global_step=self.globaliter)\n",
    "                    self.validation_summary_writer.add_scalar('Precision', self.running_avg_validation_precision[-1], global_step=self.globaliter)\n",
    "                    self.validation_summary_writer.add_scalar('Recall', self.running_avg_validation_recall[-1], global_step=self.globaliter)\n",
    "                    self.validation_summary_writer.add_scalar('Accuracy', self.running_avg_validation_accuracy[-1], global_step=self.globaliter)\n",
    "                    self.validation_summary_writer.add_scalar('Loss', self.running_avg_validation_loss[-1], global_step=self.globaliter)\n",
    "                    \n",
    "                    self.validation_summary_writer.flush()\n",
    "\n",
    "            # create statistics object and continue\n",
    "            except AttributeError:\n",
    "                self.running_avg_validation_f1 = [(sum(epoch_f1) / len(epoch_f1))]\n",
    "                self.running_avg_validation_precision = [(sum(epoch_precision) / len(epoch_precision))]\n",
    "                self.running_avg_validation_recall = [(sum(epoch_recall) / len(epoch_recall))]\n",
    "                self.running_avg_validation_accuracy = [(sum(epoch_accuracy) / len(epoch_accuracy))]\n",
    "                self.running_avg_validation_loss = [(sum(epoch_loss) / len(epoch_loss))]\n",
    "                \n",
    "            # print progress report\n",
    "            if self.verbose:\n",
    "                print(\"\\nValidation epoch: {} \\n\\tLoss: {:.6f} | F1: {:.6f} | Precision: {:.6f} | Recall: {:.6f} | Accuracy: {:.6f}\\n\".format(\n",
    "                        epoch, self.running_avg_validation_loss[-1], self.running_avg_validation_f1[-1],\n",
    "                        self.running_avg_validation_precision[-1], self.running_avg_validation_recall[-1], self.running_avg_validation_accuracy[-1]))\n",
    "        \n",
    "            # early stopping\n",
    "            if self.running_avg_validation_loss[-1] < self.min_val_loss:\n",
    "                # Save the model checkpoint\n",
    "                torch.save(self.model.state_dict(), os.path.join(self.model_dir, \"{}.pt\".format(self.model_name)))\n",
    "                self.epochs_no_improve = 0\n",
    "                self.min_val_loss = self.running_avg_validation_loss[-1]\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(\">>> Improved - saving model\\n\\n\\n\")\n",
    "\n",
    "            else:\n",
    "                self.epochs_no_improve += 1\n",
    "                if self.verbose:\n",
    "                    print(\">>> No improvement - {} consecutive epochs\\n\\n\\n\".format(self.epochs_no_improve))\n",
    "                if self.epochs_no_improve == self.n_epochs_stop:\n",
    "                    if self.verbose:\n",
    "                        print(\"\\n!!! Early stopping - {} epochs without improvement\\n\".format(self.n_epochs_stop))\n",
    "                self.running_avg_validation_loss = []\n",
    "                    \n",
    "    def train_timer(self, start, end):\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        return \"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "https://www.kaggle.com/xinruizhuang/skin-lesion-classification-acc-90-pytorch\n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n",
    "\n",
    "https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/04-utils/tensorboard\n",
    "\n",
    "https://pytorch.org/docs/stable/tensorboard.html\n",
    "\n",
    "https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce\n",
    "\n",
    "https://towardsdatascience.com/https-medium-com-dinber19-take-a-deeper-look-at-your-pytorch-model-with-the-new-tensorboard-built-in-513969cf6a72\n",
    "\n",
    "https://github.com/andyhahaha/Uncertainty-Mnist-with-Pytorch\n",
    "\n",
    "https://discuss.pytorch.org/t/using-nn-dropout2d-at-eval-time-for-modelling-uncertainty/45274\n",
    "\n",
    "https://xuwd11.github.io/Dropout_Tutorial_in_PyTorch/\n",
    "\n",
    "https://towardsdatascience.com/making-your-neural-network-say-i-dont-know-bayesian-nns-using-pyro-and-pytorch-b1c24e6ab8cd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
